{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b1984d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97948bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full path to the folder containing your CSV files\n",
    "folder_path = r\"C:\\Users\\vig10\\OneDrive\\Desktop\\Final project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83b19cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: olist_customers_dataset\n",
      "Shape: (99441, 5)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99441 entries, 0 to 99440\n",
      "Data columns (total 5 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   customer_id               99441 non-null  object\n",
      " 1   customer_unique_id        99441 non-null  object\n",
      " 2   customer_zip_code_prefix  99441 non-null  int64 \n",
      " 3   customer_city             99441 non-null  object\n",
      " 4   customer_state            99441 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 3.8+ MB\n",
      "None\n",
      "==================================================\n",
      "File: olist_geolocation_dataset\n",
      "Shape: (1000163, 5)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000163 entries, 0 to 1000162\n",
      "Data columns (total 5 columns):\n",
      " #   Column                       Non-Null Count    Dtype  \n",
      "---  ------                       --------------    -----  \n",
      " 0   geolocation_zip_code_prefix  1000163 non-null  int64  \n",
      " 1   geolocation_lat              1000163 non-null  float64\n",
      " 2   geolocation_lng              1000163 non-null  float64\n",
      " 3   geolocation_city             1000163 non-null  object \n",
      " 4   geolocation_state            1000163 non-null  object \n",
      "dtypes: float64(2), int64(1), object(2)\n",
      "memory usage: 38.2+ MB\n",
      "None\n",
      "==================================================\n",
      "File: olist_orders_dataset\n",
      "Shape: (99441, 8)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99441 entries, 0 to 99440\n",
      "Data columns (total 8 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   order_id                       99441 non-null  object\n",
      " 1   customer_id                    99441 non-null  object\n",
      " 2   order_status                   99441 non-null  object\n",
      " 3   order_purchase_timestamp       99441 non-null  object\n",
      " 4   order_approved_at              99281 non-null  object\n",
      " 5   order_delivered_carrier_date   97658 non-null  object\n",
      " 6   order_delivered_customer_date  96476 non-null  object\n",
      " 7   order_estimated_delivery_date  99441 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 6.1+ MB\n",
      "None\n",
      "==================================================\n",
      "File: olist_order_items_dataset\n",
      "Shape: (112650, 7)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112650 entries, 0 to 112649\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   order_id             112650 non-null  object \n",
      " 1   order_item_id        112650 non-null  int64  \n",
      " 2   product_id           112650 non-null  object \n",
      " 3   seller_id            112650 non-null  object \n",
      " 4   shipping_limit_date  112650 non-null  object \n",
      " 5   price                112650 non-null  float64\n",
      " 6   freight_value        112650 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 6.0+ MB\n",
      "None\n",
      "==================================================\n",
      "File: olist_order_payments_dataset\n",
      "Shape: (103886, 5)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 103886 entries, 0 to 103885\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   order_id              103886 non-null  object \n",
      " 1   payment_sequential    103886 non-null  int64  \n",
      " 2   payment_type          103886 non-null  object \n",
      " 3   payment_installments  103886 non-null  int64  \n",
      " 4   payment_value         103886 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 4.0+ MB\n",
      "None\n",
      "==================================================\n",
      "File: olist_order_reviews_dataset\n",
      "Shape: (100000, 7)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 7 columns):\n",
      " #   Column                   Non-Null Count   Dtype \n",
      "---  ------                   --------------   ----- \n",
      " 0   review_id                100000 non-null  object\n",
      " 1   order_id                 100000 non-null  object\n",
      " 2   review_score             100000 non-null  int64 \n",
      " 3   review_comment_title     11715 non-null   object\n",
      " 4   review_comment_message   41753 non-null   object\n",
      " 5   review_creation_date     100000 non-null  object\n",
      " 6   review_answer_timestamp  100000 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 5.3+ MB\n",
      "None\n",
      "==================================================\n",
      "File: olist_products_dataset\n",
      "Shape: (32951, 9)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32951 entries, 0 to 32950\n",
      "Data columns (total 9 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   product_id                  32951 non-null  object \n",
      " 1   product_category_name       32341 non-null  object \n",
      " 2   product_name_lenght         32341 non-null  float64\n",
      " 3   product_description_lenght  32341 non-null  float64\n",
      " 4   product_photos_qty          32341 non-null  float64\n",
      " 5   product_weight_g            32949 non-null  float64\n",
      " 6   product_length_cm           32949 non-null  float64\n",
      " 7   product_height_cm           32949 non-null  float64\n",
      " 8   product_width_cm            32949 non-null  float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 2.3+ MB\n",
      "None\n",
      "==================================================\n",
      "File: olist_sellers_dataset\n",
      "Shape: (3095, 4)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3095 entries, 0 to 3094\n",
      "Data columns (total 4 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   seller_id               3095 non-null   object\n",
      " 1   seller_zip_code_prefix  3095 non-null   int64 \n",
      " 2   seller_city             3095 non-null   object\n",
      " 3   seller_state            3095 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 96.8+ KB\n",
      "None\n",
      "==================================================\n",
      "File: product_category_name_translation\n",
      "Shape: (71, 2)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 71 entries, 0 to 70\n",
      "Data columns (total 2 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   product_category_name          71 non-null     object\n",
      " 1   product_category_name_english  71 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.2+ KB\n",
      "None\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store DataFrames\n",
    "dfs = {}\n",
    "\n",
    "# Iterate over each file in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.csv'):  # Check if the file is a CSV file\n",
    "        # Read the CSV file into a DataFrame\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        df = pd.read_csv(file_path)\n",
    "        # Store the DataFrame in the dictionary with the file name as part of the key\n",
    "        dfs[file_name.split('.')[0]] = df  # Use split to remove the '.csv' extension\n",
    "\n",
    "# Display the shape and basic info of each DataFrame\n",
    "for file_name, df in dfs.items():\n",
    "    print(f\"File: {file_name}\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(df.info())  # Basic information about the DataFrame\n",
    "    print(\"=\" * 50)  # Separating line for clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe620caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: olist_customers_dataset\n",
      "Shape: (99441, 5)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99441 entries, 0 to 99440\n",
      "Data columns (total 5 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   customer_id               99441 non-null  object\n",
      " 1   customer_unique_id        99441 non-null  object\n",
      " 2   customer_zip_code_prefix  99441 non-null  int64 \n",
      " 3   customer_city             99441 non-null  object\n",
      " 4   customer_state            99441 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 3.8+ MB\n",
      "None\n",
      "==================================================\n",
      "Data Completeness Check:\n",
      "customer_id                 0\n",
      "customer_unique_id          0\n",
      "customer_zip_code_prefix    0\n",
      "customer_city               0\n",
      "customer_state              0\n",
      "dtype: int64\n",
      "Duplicates Check:\n",
      "Number of duplicate rows: 0\n",
      "File: olist_geolocation_dataset\n",
      "Shape: (1000163, 5)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000163 entries, 0 to 1000162\n",
      "Data columns (total 5 columns):\n",
      " #   Column                       Non-Null Count    Dtype  \n",
      "---  ------                       --------------    -----  \n",
      " 0   geolocation_zip_code_prefix  1000163 non-null  int64  \n",
      " 1   geolocation_lat              1000163 non-null  float64\n",
      " 2   geolocation_lng              1000163 non-null  float64\n",
      " 3   geolocation_city             1000163 non-null  object \n",
      " 4   geolocation_state            1000163 non-null  object \n",
      "dtypes: float64(2), int64(1), object(2)\n",
      "memory usage: 38.2+ MB\n",
      "None\n",
      "==================================================\n",
      "Data Completeness Check:\n",
      "geolocation_zip_code_prefix    0\n",
      "geolocation_lat                0\n",
      "geolocation_lng                0\n",
      "geolocation_city               0\n",
      "geolocation_state              0\n",
      "dtype: int64\n",
      "Duplicates Check:\n",
      "Number of duplicate rows: 261831\n",
      "File: olist_orders_dataset\n",
      "Shape: (99441, 8)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99441 entries, 0 to 99440\n",
      "Data columns (total 8 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   order_id                       99441 non-null  object\n",
      " 1   customer_id                    99441 non-null  object\n",
      " 2   order_status                   99441 non-null  object\n",
      " 3   order_purchase_timestamp       99441 non-null  object\n",
      " 4   order_approved_at              99281 non-null  object\n",
      " 5   order_delivered_carrier_date   97658 non-null  object\n",
      " 6   order_delivered_customer_date  96476 non-null  object\n",
      " 7   order_estimated_delivery_date  99441 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 6.1+ MB\n",
      "None\n",
      "==================================================\n",
      "Data Completeness Check:\n",
      "order_id                            0\n",
      "customer_id                         0\n",
      "order_status                        0\n",
      "order_purchase_timestamp            0\n",
      "order_approved_at                 160\n",
      "order_delivered_carrier_date     1783\n",
      "order_delivered_customer_date    2965\n",
      "order_estimated_delivery_date       0\n",
      "dtype: int64\n",
      "Duplicates Check:\n",
      "Number of duplicate rows: 0\n",
      "File: olist_order_items_dataset\n",
      "Shape: (112650, 7)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112650 entries, 0 to 112649\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   order_id             112650 non-null  object \n",
      " 1   order_item_id        112650 non-null  int64  \n",
      " 2   product_id           112650 non-null  object \n",
      " 3   seller_id            112650 non-null  object \n",
      " 4   shipping_limit_date  112650 non-null  object \n",
      " 5   price                112650 non-null  float64\n",
      " 6   freight_value        112650 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 6.0+ MB\n",
      "None\n",
      "==================================================\n",
      "Data Completeness Check:\n",
      "order_id               0\n",
      "order_item_id          0\n",
      "product_id             0\n",
      "seller_id              0\n",
      "shipping_limit_date    0\n",
      "price                  0\n",
      "freight_value          0\n",
      "dtype: int64\n",
      "Duplicates Check:\n",
      "Number of duplicate rows: 0\n",
      "File: olist_order_payments_dataset\n",
      "Shape: (103886, 5)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 103886 entries, 0 to 103885\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   order_id              103886 non-null  object \n",
      " 1   payment_sequential    103886 non-null  int64  \n",
      " 2   payment_type          103886 non-null  object \n",
      " 3   payment_installments  103886 non-null  int64  \n",
      " 4   payment_value         103886 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 4.0+ MB\n",
      "None\n",
      "==================================================\n",
      "Data Completeness Check:\n",
      "order_id                0\n",
      "payment_sequential      0\n",
      "payment_type            0\n",
      "payment_installments    0\n",
      "payment_value           0\n",
      "dtype: int64\n",
      "Duplicates Check:\n",
      "Number of duplicate rows: 0\n",
      "File: olist_order_reviews_dataset\n",
      "Shape: (100000, 7)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 7 columns):\n",
      " #   Column                   Non-Null Count   Dtype \n",
      "---  ------                   --------------   ----- \n",
      " 0   review_id                100000 non-null  object\n",
      " 1   order_id                 100000 non-null  object\n",
      " 2   review_score             100000 non-null  int64 \n",
      " 3   review_comment_title     11715 non-null   object\n",
      " 4   review_comment_message   41753 non-null   object\n",
      " 5   review_creation_date     100000 non-null  object\n",
      " 6   review_answer_timestamp  100000 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 5.3+ MB\n",
      "None\n",
      "==================================================\n",
      "Data Completeness Check:\n",
      "review_id                      0\n",
      "order_id                       0\n",
      "review_score                   0\n",
      "review_comment_title       88285\n",
      "review_comment_message     58247\n",
      "review_creation_date           0\n",
      "review_answer_timestamp        0\n",
      "dtype: int64\n",
      "Duplicates Check:\n",
      "Number of duplicate rows: 0\n",
      "File: olist_products_dataset\n",
      "Shape: (32951, 9)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32951 entries, 0 to 32950\n",
      "Data columns (total 9 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   product_id                  32951 non-null  object \n",
      " 1   product_category_name       32341 non-null  object \n",
      " 2   product_name_lenght         32341 non-null  float64\n",
      " 3   product_description_lenght  32341 non-null  float64\n",
      " 4   product_photos_qty          32341 non-null  float64\n",
      " 5   product_weight_g            32949 non-null  float64\n",
      " 6   product_length_cm           32949 non-null  float64\n",
      " 7   product_height_cm           32949 non-null  float64\n",
      " 8   product_width_cm            32949 non-null  float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 2.3+ MB\n",
      "None\n",
      "==================================================\n",
      "Data Completeness Check:\n",
      "product_id                      0\n",
      "product_category_name         610\n",
      "product_name_lenght           610\n",
      "product_description_lenght    610\n",
      "product_photos_qty            610\n",
      "product_weight_g                2\n",
      "product_length_cm               2\n",
      "product_height_cm               2\n",
      "product_width_cm                2\n",
      "dtype: int64\n",
      "Duplicates Check:\n",
      "Number of duplicate rows: 0\n",
      "File: olist_sellers_dataset\n",
      "Shape: (3095, 4)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3095 entries, 0 to 3094\n",
      "Data columns (total 4 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   seller_id               3095 non-null   object\n",
      " 1   seller_zip_code_prefix  3095 non-null   int64 \n",
      " 2   seller_city             3095 non-null   object\n",
      " 3   seller_state            3095 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 96.8+ KB\n",
      "None\n",
      "==================================================\n",
      "Data Completeness Check:\n",
      "seller_id                 0\n",
      "seller_zip_code_prefix    0\n",
      "seller_city               0\n",
      "seller_state              0\n",
      "dtype: int64\n",
      "Duplicates Check:\n",
      "Number of duplicate rows: 0\n",
      "File: product_category_name_translation\n",
      "Shape: (71, 2)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 71 entries, 0 to 70\n",
      "Data columns (total 2 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   product_category_name          71 non-null     object\n",
      " 1   product_category_name_english  71 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.2+ KB\n",
      "None\n",
      "==================================================\n",
      "Data Completeness Check:\n",
      "product_category_name            0\n",
      "product_category_name_english    0\n",
      "dtype: int64\n",
      "Duplicates Check:\n",
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Data cleaning checks for each DataFrame\n",
    "for file_name, df in dfs.items():\n",
    "    print(f\"File: {file_name}\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(df.info())  # Basic information about the DataFrame\n",
    "    print(\"=\" * 50)  # Separating line for clarity\n",
    "\n",
    "    # Data Completeness Check\n",
    "    print(\"Data Completeness Check:\")\n",
    "    print(df.isnull().sum())  # Check for missing values\n",
    "\n",
    "    # Duplicates Check\n",
    "    print(\"Duplicates Check:\")\n",
    "    print(\"Number of duplicate rows:\", df.duplicated().sum())  # Check for duplicates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42b0e68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in olist_order_items_dataset:\n",
      "order_id               0\n",
      "order_item_id          0\n",
      "product_id             0\n",
      "seller_id              0\n",
      "shipping_limit_date    0\n",
      "price                  0\n",
      "freight_value          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Data Completeness Check\n",
    "order_items_missing_values = dfs['olist_order_items_dataset'].isnull().sum()\n",
    "print(\"Missing values in olist_order_items_dataset:\")\n",
    "print(order_items_missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04c2da55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in olist_order_payments_dataset:\n",
      "order_id                0\n",
      "payment_sequential      0\n",
      "payment_type            0\n",
      "payment_installments    0\n",
      "payment_value           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Data Completeness Check\n",
    "order_payments_missing_values = dfs['olist_order_payments_dataset'].isnull().sum()\n",
    "print(\"Missing values in olist_order_payments_dataset:\")\n",
    "print(order_payments_missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11c79ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows in olist_order_items_dataset: 0\n"
     ]
    }
   ],
   "source": [
    "# Duplicates Check\n",
    "order_items_duplicates = dfs['olist_order_items_dataset'].duplicated().sum()\n",
    "print(\"Number of duplicate rows in olist_order_items_dataset:\", order_items_duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a16d96a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows in olist_order_payments_dataset: 0\n"
     ]
    }
   ],
   "source": [
    "# Duplicates Check\n",
    "order_payments_duplicates = dfs['olist_order_payments_dataset'].duplicated().sum()\n",
    "print(\"Number of duplicate rows in olist_order_payments_dataset:\", order_payments_duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5be810ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All order_id values in olist_order_items exist in olist_orders: True\n"
     ]
    }
   ],
   "source": [
    "# Outliers Check with olist_orders_dataset\n",
    "order_items_orders_check = dfs['olist_order_items_dataset']['order_id'].isin(dfs['olist_orders_dataset']['order_id']).all()\n",
    "print(\"All order_id values in olist_order_items exist in olist_orders:\", order_items_orders_check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "557973ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All product_id values in olist_order_items exist in olist_products: True\n"
     ]
    }
   ],
   "source": [
    "# Outliers Consistency Check with olist_products_dataset\n",
    "order_items_products_check = dfs['olist_order_items_dataset']['product_id'].isin(dfs['olist_products_dataset']['product_id']).all()\n",
    "print(\"All product_id values in olist_order_items exist in olist_products:\", order_items_products_check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "239253f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All seller_id values in olist_order_items exist in olist_sellers: True\n"
     ]
    }
   ],
   "source": [
    "# Outliers Consistency Check with olist_sellers_dataset\n",
    "order_items_sellers_check = dfs['olist_order_items_dataset']['seller_id'].isin(dfs['olist_sellers_dataset']['seller_id']).all()\n",
    "print(\"All seller_id values in olist_order_items exist in olist_sellers:\", order_items_sellers_check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "064b7c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of unique seller IDs in olist_order_items: 3095\n",
      "Count of unique seller IDs in olist_sellers: 3095\n",
      "All unique seller IDs in olist_order_items match unique seller IDs in olist_sellers: True\n"
     ]
    }
   ],
   "source": [
    "# Count the unique seller IDs in each dataset\n",
    "order_items_unique_count = len(dfs['olist_order_items_dataset']['seller_id'].unique())\n",
    "sellers_unique_count = len(dfs['olist_sellers_dataset']['seller_id'].unique())\n",
    "\n",
    "# Check if all unique seller IDs in olist_order_items match unique seller IDs in olist_sellers\n",
    "unique_ids_match = order_items_unique_count == sellers_unique_count\n",
    "\n",
    "print(\"Count of unique seller IDs in olist_order_items:\", order_items_unique_count)\n",
    "print(\"Count of unique seller IDs in olist_sellers:\", sellers_unique_count)\n",
    "print(\"All unique seller IDs in olist_order_items match unique seller IDs in olist_sellers:\", unique_ids_match)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e36c637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All order_id values in olist_order_items exist in olist_orders: True\n",
      "Number of unique order IDs in olist_order_items matches olist_orders: False\n"
     ]
    }
   ],
   "source": [
    "# Data Consistency Check with olist_orders_dataset including uniqueness\n",
    "order_items_orders_check = dfs['olist_order_items_dataset']['order_id'].isin(dfs['olist_orders_dataset']['order_id']).all()\n",
    "order_items_unique_orders_check = dfs['olist_order_items_dataset']['order_id'].nunique() == dfs['olist_orders_dataset']['order_id'].nunique()\n",
    "\n",
    "print(\"All order_id values in olist_order_items exist in olist_orders:\", order_items_orders_check)\n",
    "print(\"Number of unique order IDs in olist_order_items matches olist_orders:\", order_items_unique_orders_check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ea8c968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values of 'order_item_id': [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]\n",
      "Unique values of 'payment_sequential': [ 1  2  4  5  3  8  6  7 10 11 17 19 27 12  9 15 13 14 16 25 22 26 29 28\n",
      " 18 21 24 23 20]\n"
     ]
    }
   ],
   "source": [
    "# Unique values of 'order_item_id'\n",
    "unique_order_item_ids = dfs['olist_order_items_dataset']['order_item_id'].unique()\n",
    "\n",
    "# Unique values of 'payment_sequential'\n",
    "unique_payment_sequential = dfs['olist_order_payments_dataset']['payment_sequential'].unique()\n",
    "\n",
    "print(\"Unique values of 'order_item_id':\", unique_order_item_ids)\n",
    "print(\"Unique values of 'payment_sequential':\", unique_payment_sequential)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "371b7c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique order IDs in olist_order_payments_dataset: 99440\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of unique order IDs\n",
    "unique_order_ids = dfs['olist_order_payments_dataset']['order_id'].nunique()\n",
    "print(\"Number of unique order IDs in olist_order_payments_dataset:\", unique_order_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31c84c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique order IDs in olist_order_items_dataset: 98666\n",
      "Number of unique order IDs in olist_order_payments_dataset: 99440\n"
     ]
    }
   ],
   "source": [
    "# Number of unique order IDs in olist_order_items_dataset\n",
    "unique_order_ids_order_items = dfs['olist_order_items_dataset']['order_id'].nunique()\n",
    "\n",
    "# Number of unique order IDs in olist_order_payments_dataset\n",
    "unique_order_ids_payments = dfs['olist_order_payments_dataset']['order_id'].nunique()\n",
    "\n",
    "print(f\"Number of unique order IDs in olist_order_items_dataset: {unique_order_ids_order_items}\")\n",
    "print(f\"Number of unique order IDs in olist_order_payments_dataset: {unique_order_ids_payments}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4667f765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique order IDs in olist_orders_dataset: 99441\n"
     ]
    }
   ],
   "source": [
    "# Number of unique order IDs in olist_orders_dataset\n",
    "unique_order_ids_orders = dfs['olist_orders_dataset']['order_id'].nunique()\n",
    "\n",
    "print(f\"Number of unique order IDs in olist_orders_dataset: {unique_order_ids_orders}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4e554ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of order IDs in olist_orders_dataset: 99441\n"
     ]
    }
   ],
   "source": [
    "# Total number of order IDs in olist_orders_dataset\n",
    "total_order_ids = len(dfs['olist_orders_dataset']['order_id'])\n",
    "\n",
    "print(f\"Total number of order IDs in olist_orders_dataset: {total_order_ids}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ea354d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Order IDs:\n",
      "                     missing_order_id\n",
      "0    ef32bb24f4e81a29a305e5285c8d3d34\n",
      "1    b90cc9e10252911c2092a1e49794aa13\n",
      "2    186d3cd768be1890d832106f914ba37c\n",
      "3    a0c1632c3bd45c48bed924a7dae3a664\n",
      "4    ca9d82b594244464dddfac0959180268\n",
      "..                                ...\n",
      "770  a3777b94ef07749f031ade4ae824ddb2\n",
      "771  0130f0f71fb0e831d18e6a3b33a3a50c\n",
      "772  43c8d05a1478e794217ad3b39398022a\n",
      "773  ea844c92cf978ea23321fa7fe5871761\n",
      "774  791d454dd290baaf30d599c6183d7489\n",
      "\n",
      "[775 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Get unique order IDs from order items and order payments datasets\n",
    "order_ids_order_items = set(dfs['olist_order_items_dataset']['order_id'])\n",
    "order_ids_payments = set(dfs['olist_order_payments_dataset']['order_id'])\n",
    "\n",
    "# Find missing order IDs\n",
    "missing_order_ids = order_ids_payments - order_ids_order_items\n",
    "\n",
    "# Create a DataFrame to store missing order IDs\n",
    "missing_order_ids_df = pd.DataFrame({'missing_order_id': list(missing_order_ids)})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "missing_order_ids_df.to_csv('missing_order_ids.csv', index=False)\n",
    "\n",
    "# Display the missing order IDs\n",
    "print(\"Missing Order IDs:\")\n",
    "print(missing_order_ids_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12785332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Order ID: {'bfbd0f9bdef84302105ad712db648a6c'}\n"
     ]
    }
   ],
   "source": [
    "# Get unique order IDs from order and order payments datasets\n",
    "order_ids_orders = set(dfs['olist_orders_dataset']['order_id'])\n",
    "order_ids_payments = set(dfs['olist_order_payments_dataset']['order_id'])\n",
    "\n",
    "# Find the missing order ID (assuming there's only one)\n",
    "missing_order_id = order_ids_orders-order_ids_payments\n",
    "\n",
    "# Print the missing order ID\n",
    "print(\"Missing Order ID:\", missing_order_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4204e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of order IDs where Payment Value matches Order Value: 76666\n",
      "Number of order IDs where Payment Value does not match Order Value: 21999\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Merge order items and payments on order_id\n",
    "merged_df = pd.merge(dfs['olist_order_items_dataset'], dfs['olist_order_payments_dataset'], on='order_id', how='inner')\n",
    "\n",
    "# Calculate total payment value in olist_order_payments_dataset\n",
    "total_payment = dfs['olist_order_payments_dataset'].groupby('order_id')['payment_value'].sum()\n",
    "\n",
    "# Calculate total order value in olist_order_items_dataset (sum of price and freight_value)\n",
    "total_order_value = merged_df.groupby('order_id').apply(lambda x: (x['price'] + x['freight_value']).sum())\n",
    "\n",
    "# Compare total payment value with total order value for each order ID\n",
    "matched_count = 0\n",
    "unmatched_count = 0\n",
    "for order_id in merged_df['order_id'].unique():\n",
    "    payment_value = total_payment.get(order_id, 0)\n",
    "    order_value = total_order_value.get(order_id, 0)\n",
    "    if payment_value == order_value:\n",
    "        matched_count += 1\n",
    "    else:\n",
    "        unmatched_count += 1\n",
    "\n",
    "print(f\"Number of order IDs where Payment Value matches Order Value: {matched_count}\")\n",
    "print(f\"Number of order IDs where Payment Value does not match Order Value: {unmatched_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "385fe593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of orders with unmatched payment and order values and payment sequential count > 1: 2936\n"
     ]
    }
   ],
   "source": [
    "# Merge order items and payments on order_id\n",
    "merged_df = pd.merge(dfs['olist_order_items_dataset'], dfs['olist_order_payments_dataset'], on='order_id', how='inner')\n",
    "\n",
    "# Calculate total payment value in olist_order_payments_dataset\n",
    "total_payment = dfs['olist_order_payments_dataset'].groupby('order_id')['payment_value'].sum()\n",
    "\n",
    "# Calculate total order value in olist_order_items_dataset (sum of price and freight_value)\n",
    "total_order_value = merged_df.groupby('order_id').apply(lambda x: (x['price'] + x['freight_value']).sum())\n",
    "\n",
    "# Get the payment sequential count for each order\n",
    "payment_sequential_count = dfs['olist_order_payments_dataset'].groupby('order_id')['payment_sequential'].nunique()\n",
    "\n",
    "# Compare total payment value with total order value for each order ID\n",
    "unmatched_count = 0\n",
    "for order_id in merged_df['order_id'].unique():\n",
    "    payment_value = total_payment.get(order_id, 0)\n",
    "    order_value = total_order_value.get(order_id, 0)\n",
    "    if payment_value != order_value and payment_sequential_count.get(order_id, 0) > 1:\n",
    "        unmatched_count += 1\n",
    "\n",
    "print(f\"Number of orders with unmatched payment and order values and payment sequential count > 1: {unmatched_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a5a318a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakdown of payment type for unmatched payments:\n",
      "credit_card: 15984\n",
      "boleto: 3947\n",
      "voucher: 1759\n",
      "debit_card: 309\n"
     ]
    }
   ],
   "source": [
    "# Merge order items and payments on order_id\n",
    "merged_df = pd.merge(dfs['olist_order_items_dataset'], dfs['olist_order_payments_dataset'], on='order_id', how='inner')\n",
    "\n",
    "# Calculate total payment value in olist_order_payments_dataset\n",
    "total_payment = dfs['olist_order_payments_dataset'].groupby('order_id')['payment_value'].sum()\n",
    "\n",
    "# Calculate total order value in olist_order_items_dataset (sum of price and freight_value)\n",
    "total_order_value = merged_df.groupby('order_id').apply(lambda x: (x['price'] + x['freight_value']).sum())\n",
    "\n",
    "# Get the payment type for each order\n",
    "payment_type = dfs['olist_order_payments_dataset'].groupby('order_id')['payment_type'].first()\n",
    "\n",
    "# Compare total payment value with total order value for each order ID\n",
    "unmatched_payment_info = {}\n",
    "for order_id in merged_df['order_id'].unique():\n",
    "    payment_value = total_payment.get(order_id, 0)\n",
    "    order_value = total_order_value.get(order_id, 0)\n",
    "    if payment_value != order_value:\n",
    "        payment_type_order = payment_type.get(order_id)\n",
    "        if payment_type_order not in unmatched_payment_info:\n",
    "            unmatched_payment_info[payment_type_order] = 1\n",
    "        else:\n",
    "            unmatched_payment_info[payment_type_order] += 1\n",
    "\n",
    "print(\"Breakdown of payment type for unmatched payments:\")\n",
    "for payment_type, count in unmatched_payment_info.items():\n",
    "    print(f\"{payment_type}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "667d5407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unmatched payments: 21999\n",
      "Outcomes for unmatched payments:\n",
      "DELIVERY_STATUS:\n",
      "delivered: 21514\n",
      "shipped: 227\n",
      "canceled: 113\n",
      "invoiced: 84\n",
      "processing: 60\n",
      "approved: 1\n"
     ]
    }
   ],
   "source": [
    "# Merge order items and payments on order_id\n",
    "merged_df = pd.merge(dfs['olist_order_items_dataset'], dfs['olist_order_payments_dataset'], on='order_id', how='inner')\n",
    "\n",
    "# Calculate total payment value in olist_order_payments_dataset\n",
    "total_payment = dfs['olist_order_payments_dataset'].groupby('order_id')['payment_value'].sum()\n",
    "\n",
    "# Calculate total order value in olist_order_items_dataset (sum of price and freight_value)\n",
    "total_order_value = merged_df.groupby('order_id').apply(lambda x: (x['price'] + x['freight_value']).sum())\n",
    "\n",
    "# Get the payment type for each order\n",
    "payment_type = dfs['olist_order_payments_dataset'].groupby('order_id')['payment_type'].first()\n",
    "\n",
    "# Get the order status for each order\n",
    "order_status = dfs['olist_orders_dataset'].set_index('order_id')['order_status']\n",
    "\n",
    "# Get the delivery status for each order\n",
    "delivery_status = dfs['olist_orders_dataset'].set_index('order_id')['order_status']\n",
    "\n",
    "# Initialize counters for unmatched payments\n",
    "unmatched_payment_count = 0\n",
    "\n",
    "# Initialize dictionaries to store outcomes for each unmatched payment\n",
    "unmatched_payment_outcomes = {'DELIVERY_STATUS': []}\n",
    "\n",
    "# Compare total payment value with total order value for each order ID\n",
    "for order_id in merged_df['order_id'].unique():\n",
    "    payment_value = total_payment.get(order_id, 0)\n",
    "    order_value = total_order_value.get(order_id, 0)\n",
    "    if payment_value != order_value:\n",
    "        unmatched_payment_count += 1\n",
    "        order_status_order = order_status.get(order_id)\n",
    "        delivery_status_order = delivery_status.get(order_id)\n",
    "        unmatched_payment_outcomes['DELIVERY_STATUS'].append(delivery_status_order)\n",
    "        \n",
    "print(f\"Number of unmatched payments: {unmatched_payment_count}\")\n",
    "print(\"Outcomes for unmatched payments:\")\n",
    "for outcome_type, outcomes in unmatched_payment_outcomes.items():\n",
    "    outcome_counts = pd.Series(outcomes).value_counts()\n",
    "    print(f\"{outcome_type}:\")\n",
    "    for outcome, count in outcome_counts.items():\n",
    "        print(f\"{outcome}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8eca9de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unmatched payments: 21999\n",
      "Number of orders appearing more than once in the order list with unmatched payments: 2745\n"
     ]
    }
   ],
   "source": [
    "# Merge order items and payments on order_id\n",
    "merged_df = pd.merge(dfs['olist_order_items_dataset'], dfs['olist_order_payments_dataset'], on='order_id', how='inner')\n",
    "\n",
    "# Calculate total payment value in olist_order_payments_dataset\n",
    "total_payment = dfs['olist_order_payments_dataset'].groupby('order_id')['payment_value'].sum()\n",
    "\n",
    "# Calculate total order value in olist_order_items_dataset (sum of price and freight_value)\n",
    "total_order_value = merged_df.groupby('order_id').apply(lambda x: (x['price'] + x['freight_value']).sum())\n",
    "\n",
    "# Get the count of items for each order ID\n",
    "order_item_counts = dfs['olist_order_items_dataset']['order_id'].value_counts()\n",
    "\n",
    "# Initialize counter for unmatched payments and orders appearing more than once\n",
    "unmatched_payment_count = 0\n",
    "orders_appearing_more_than_once = 0\n",
    "\n",
    "# Compare total payment value with total order value for each order ID\n",
    "for order_id in merged_df['order_id'].unique():\n",
    "    payment_value = total_payment.get(order_id, 0)\n",
    "    order_value = total_order_value.get(order_id, 0)\n",
    "    if payment_value != order_value:\n",
    "        unmatched_payment_count += 1\n",
    "        if order_item_counts.get(order_id, 0) > 1:\n",
    "            orders_appearing_more_than_once += 1\n",
    "\n",
    "print(f\"Number of unmatched payments: {unmatched_payment_count}\")\n",
    "print(f\"Number of orders appearing more than once in the order list with unmatched payments: {orders_appearing_more_than_once}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9d601a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unmatched payments: 21999\n",
      "Number of unmatched payments with payment_installments > 1: 10367\n"
     ]
    }
   ],
   "source": [
    "# Merge order items and payments on order_id\n",
    "merged_df = pd.merge(dfs['olist_order_items_dataset'], dfs['olist_order_payments_dataset'], on='order_id', how='inner')\n",
    "\n",
    "# Calculate total payment value in olist_order_payments_dataset\n",
    "total_payment = dfs['olist_order_payments_dataset'].groupby('order_id')['payment_value'].sum()\n",
    "\n",
    "# Calculate total order value in olist_order_items_dataset (sum of price and freight_value)\n",
    "total_order_value = merged_df.groupby('order_id').apply(lambda x: (x['price'] + x['freight_value']).sum())\n",
    "\n",
    "# Initialize counter for unmatched payments and unmatched payments with payment_installments > 1\n",
    "unmatched_payment_count = 0\n",
    "unmatched_payment_installments_count = 0\n",
    "\n",
    "# Compare total payment value with total order value for each order ID\n",
    "for order_id in merged_df['order_id'].unique():\n",
    "    payment_value = total_payment.get(order_id, 0)\n",
    "    order_value = total_order_value.get(order_id, 0)\n",
    "    if payment_value != order_value:\n",
    "        unmatched_payment_count += 1\n",
    "        if dfs['olist_order_payments_dataset'].loc[dfs['olist_order_payments_dataset']['order_id'] == order_id, 'payment_installments'].iloc[0] > 1:\n",
    "            unmatched_payment_installments_count += 1\n",
    "\n",
    "print(f\"Number of unmatched payments: {unmatched_payment_count}\")\n",
    "print(f\"Number of unmatched payments with payment_installments > 1: {unmatched_payment_installments_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8cb5ac27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of payment_installments < 1: 2\n"
     ]
    }
   ],
   "source": [
    "# Filter payments where payment_installments < 1\n",
    "filtered_payments = dfs['olist_order_payments_dataset'][dfs['olist_order_payments_dataset']['payment_installments'] < 1]\n",
    "\n",
    "# Get the count of payments with payment_installments < 1\n",
    "count_payment_installments_less_than_1 = filtered_payments.shape[0]\n",
    "\n",
    "print(\"Number of payment_installments < 1:\", count_payment_installments_less_than_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5895e377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unmatched payments: 21999\n",
      "Number of unmatched payments with payment_installments >= 1: 21999\n"
     ]
    }
   ],
   "source": [
    "# Merge order items and payments on order_id\n",
    "merged_df = pd.merge(dfs['olist_order_items_dataset'], dfs['olist_order_payments_dataset'], on='order_id', how='inner')\n",
    "\n",
    "# Calculate total payment value in olist_order_payments_dataset\n",
    "total_payment = dfs['olist_order_payments_dataset'].groupby('order_id')['payment_value'].sum()\n",
    "\n",
    "# Calculate total order value in olist_order_items_dataset (sum of price and freight_value)\n",
    "total_order_value = merged_df.groupby('order_id').apply(lambda x: (x['price'] + x['freight_value']).sum())\n",
    "\n",
    "# Initialize counter for unmatched payments and unmatched payments with payment_installments >= 1\n",
    "unmatched_payment_count = 0\n",
    "unmatched_payment_installments_count = 0\n",
    "\n",
    "# Compare total payment value with total order value for each order ID\n",
    "for order_id in merged_df['order_id'].unique():\n",
    "    payment_value = total_payment.get(order_id, 0)\n",
    "    order_value = total_order_value.get(order_id, 0)\n",
    "    if payment_value != order_value:\n",
    "        unmatched_payment_count += 1\n",
    "        if dfs['olist_order_payments_dataset'].loc[dfs['olist_order_payments_dataset']['order_id'] == order_id, 'payment_installments'].iloc[0] >= 1:\n",
    "            unmatched_payment_installments_count += 1\n",
    "\n",
    "print(f\"Number of unmatched payments: {unmatched_payment_count}\")\n",
    "print(f\"Number of unmatched payments with payment_installments >= 1: {unmatched_payment_installments_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec75daf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matched payments with payment_installments >= 1: 76664\n",
      "Number of matched payments with payment_installments < 1: 2\n",
      "Number of unmatched payments with payment_installments >= 1: 21999\n",
      "Number of unmatched payments with payment_installments < 1: 0\n"
     ]
    }
   ],
   "source": [
    "# Merge order items and payments on order_id\n",
    "merged_df = pd.merge(dfs['olist_order_items_dataset'], dfs['olist_order_payments_dataset'], on='order_id', how='inner')\n",
    "\n",
    "# Calculate total payment value in olist_order_payments_dataset\n",
    "total_payment = dfs['olist_order_payments_dataset'].groupby('order_id')['payment_value'].sum()\n",
    "\n",
    "# Calculate total order value in olist_order_items_dataset (sum of price and freight_value)\n",
    "total_order_value = merged_df.groupby('order_id').apply(lambda x: (x['price'] + x['freight_value']).sum())\n",
    "\n",
    "# Initialize counter for matched and unmatched payments with payment_installments > 1 and < 1\n",
    "matched_payment_installments_gt1 = 0\n",
    "unmatched_payment_installments_gt1 = 0\n",
    "matched_payment_installments_lt1 = 0\n",
    "unmatched_payment_installments_lt1 = 0\n",
    "\n",
    "# Compare total payment value with total order value for each order ID\n",
    "for order_id in merged_df['order_id'].unique():\n",
    "    payment_value = total_payment.get(order_id, 0)\n",
    "    order_value = total_order_value.get(order_id, 0)\n",
    "    if payment_value == order_value:\n",
    "        if dfs['olist_order_payments_dataset'].loc[dfs['olist_order_payments_dataset']['order_id'] == order_id, 'payment_installments'].iloc[0] >= 1:\n",
    "            matched_payment_installments_gt1 += 1\n",
    "        else:\n",
    "            matched_payment_installments_lt1 += 1\n",
    "    else:\n",
    "        if dfs['olist_order_payments_dataset'].loc[dfs['olist_order_payments_dataset']['order_id'] == order_id, 'payment_installments'].iloc[0] >= 1:\n",
    "            unmatched_payment_installments_gt1 += 1\n",
    "        else:\n",
    "            unmatched_payment_installments_lt1 += 1\n",
    "\n",
    "print(f\"Number of matched payments with payment_installments >= 1: {matched_payment_installments_gt1}\")\n",
    "print(f\"Number of matched payments with payment_installments < 1: {matched_payment_installments_lt1}\")\n",
    "print(f\"Number of unmatched payments with payment_installments >= 1: {unmatched_payment_installments_gt1}\")\n",
    "print(f\"Number of unmatched payments with payment_installments < 1: {unmatched_payment_installments_lt1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b062563e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of differences DataFrame:\n",
      "                               order_id  difference\n",
      "21507  fa65dad1b0e818e3ccc5cb0e39231352   -12823.72\n",
      "6513   4bfcba9e084f46c8e3cb49b0fa6e6159   -10370.64\n",
      "5989   465c2e1bee4561cb39e0db8c5993aafc    -9673.84\n",
      "21008  f489949dbe23cf9313deb342913ece0c    -8618.76\n",
      "6009   4689b1816de42507a7d63a4617383c59    -6884.15\n",
      "\n",
      "Tail of differences DataFrame:\n",
      "                               order_id  difference\n",
      "9638   70b7e94ea46d3e8b5bc12a50186edaf0       61.69\n",
      "13069  996c7e73600ad3723e8627ab7bef81e4       76.53\n",
      "9637   70b742795bc441e94a44a084b6d9ce7a      111.89\n",
      "9431   6e5fe7366a2e1bfbf3257dba0af1267f      119.01\n",
      "17729  ce6d150fb29ada17d2082f4847107665      182.81\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Merge order items and payments on order_id\n",
    "merged_df = pd.merge(dfs['olist_order_items_dataset'], dfs['olist_order_payments_dataset'], on='order_id', how='inner')\n",
    "\n",
    "# Calculate total payment value in olist_order_payments_dataset\n",
    "total_payment = dfs['olist_order_payments_dataset'].groupby('order_id')['payment_value'].sum()\n",
    "\n",
    "# Calculate total order value in olist_order_items_dataset (sum of price and freight_value)\n",
    "total_order_value = merged_df.groupby('order_id').apply(lambda x: (x['price'] + x['freight_value']).sum())\n",
    "\n",
    "# Initialize an empty list to store differences\n",
    "differences = []\n",
    "\n",
    "# Compare total payment value with total order value for each order ID\n",
    "for order_id in merged_df['order_id'].unique():\n",
    "    payment_value = total_payment.get(order_id, 0)\n",
    "    order_value = total_order_value.get(order_id, 0)\n",
    "    if payment_value != order_value:\n",
    "        difference = payment_value - order_value\n",
    "        differences.append({'order_id': order_id, 'difference': difference})\n",
    "\n",
    "# Create a DataFrame from the list of differences\n",
    "differences_df = pd.DataFrame(differences)\n",
    "\n",
    "# Sort the differences DataFrame based on the \"difference\" column\n",
    "differences_df = differences_df.sort_values(by='difference')\n",
    "\n",
    "# Display head and tail of differences DataFrame\n",
    "print(\"Head of differences DataFrame:\")\n",
    "print(differences_df.head())\n",
    "\n",
    "print(\"\\nTail of differences DataFrame:\")\n",
    "print(differences_df.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcce3a67",
   "metadata": {},
   "source": [
    "#key summary \n",
    "\n",
    "There are 775 missing entries in the olist order_items (take note the one missing id in olist order_payment is present in here)\n",
    "There is one missing id/entry in the olist order_payment - bfbd0f9bdef84302105ad712db648a6c\n",
    "\n",
    "The payments tally for 76666\n",
    "The payments do not tally for 21999\n",
    "\n",
    "So far data validation checks have shown that: \n",
    "The unmatched payment tally were not influenced by factors like interest from installment, the sequential modes of payment, the different payment type made by customer or due to the number of items being purchased. \n",
    "\n",
    "Further analysis showed that differences were not minute and were pretty large. \n",
    "\n",
    "Shipping Limit date will be dropped from the olist order_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4da4f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Define the database connection parameters\n",
    "db_params = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"dbname\": \"Fp\",       # Replace with your desired database name\n",
    "    \"user\": \"postgres\",       # Replace with your PostgreSQL username\n",
    "    \"password\": \"admin\",      # Replace with your PostgreSQL password\n",
    "    \"port\": \"5432\"            # Replace with your PostgreSQL port\n",
    "}\n",
    "\n",
    "# Construct the SQLAlchemy connection string using db_params\n",
    "connection_string = f\"postgresql+psycopg2://{db_params['user']}:{db_params['password']}@{db_params['host']}:{db_params['port']}/{db_params['dbname']}\"\n",
    "\n",
    "# Create the engine\n",
    "engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de295fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unnecessary column dropped\n",
    "\n",
    "dfs['olist_order_items_dataset'] = dfs['olist_order_items_dataset'].drop(columns=['shipping_limit_date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "328c1f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transfer completed successfully!\n"
     ]
    }
   ],
   "source": [
    "#Transfer the DataFrames to your PostgreSQL database\n",
    "dfs['olist_order_items_dataset'].to_sql('olist_order_items', engine, if_exists='replace', index=False)\n",
    "dfs['olist_order_payments_dataset'].to_sql('olist_order_payments', engine, if_exists='replace', index=False)\n",
    "print(\"Data transfer completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb5827b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
